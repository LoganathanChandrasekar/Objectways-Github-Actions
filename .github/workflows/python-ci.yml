name: Python CI/CD

on:
  workflow_call:
    inputs:
      python-version: { type: string, default: '3.12' }
      working-directory: { type: string, default: '.' }
      aws-region: { type: string, required: true }
      deploy-runner: { type: string, default: 'self-hosted' }
      s3-bucket: { type: string, required: true }
      deploy-path: { type: string, required: true }
      env-source-path: { type: string, required: true }
      python-entry-point: { type: string, default: 'app/main.py' }
      debug_enabled: { type: boolean, default: false }
      serviceName: { type: string, default: 'python-backend.service' }
    secrets:
      aws-role-arn: { required: true }

permissions:
  contents: read
  id-token: write

jobs:
  build-test:
    runs-on: ${{ inputs.deploy-runner }}
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Install rsync
        run: |
          sudo apt-get update -y
          sudo apt-get install -y rsync

      - name: Set up Python
        id: setup-python # Added ID to use outputs later if needed
        run: |
          echo "Using system python: $(python3 --version)"
          # Verify venv module is available
          python3 -m venv --help > /dev/null || (sudo apt-get update && sudo apt-get install python3.12-venv -y)
          # Output the actual version for the cache key
          echo "python-version=$(python3 -c 'import platform; print(platform.python_version())')" >> $GITHUB_OUTPUT

      - name: Cache Python Dependencies
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57
        id: cache-python-deps
        with:
          path: ${{ inputs.working-directory }}/.venv
          # FIXED: Uses the actual system python version we detected above
          key: ${{ runner.os }}-python-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-python-${{ steps.setup-python.outputs.python-version }}-
              
      - name: Install Dependencies & Audit
        run: |
          # Create and use a local virtual environment
          python3 -m venv .venv
          source .venv/bin/activate
          python3 -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install safety
          safety check -r requirements.txt || echo "Safety check found issues, continuing..."
        working-directory: ${{ inputs.working-directory }}

      - name: Lint & Format (Ruff)
        run: |
          source .venv/bin/activate # Activate venv for tools
          pip install ruff
          ruff check . || true # Continue on error as per your request
          ruff format .
        working-directory: ${{ inputs.working-directory }}
        continue-on-error: true

      - name: Test & Coverage
        run: |
          source .venv/bin/activate # Activate venv
          if [ -f pytest.ini ] || [ -d tests ]; then
            pip install pytest pytest-cov
            pytest --cov=app --cov-report=xml --cov-report=term-missing --cov-fail-under=85
          fi
        working-directory: ${{ inputs.working-directory }}

      - name: Prepare Artifact
        run: |
          mkdir -p deploy-package
          rsync -a ./ deploy-package/ --exclude .git --exclude .venv --exclude __pycache__
          cd deploy-package
          tar -czf ../build-${{ github.sha }}.tar.gz .
        working-directory: ${{ inputs.working-directory }}

      - name: AWS Auth
        if: success() && !env.ACT
        uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502
        with:
          role-to-assume: ${{ secrets.aws-role-arn }}
          aws-region: ${{ inputs.aws-region }}

      - name: Upload to S3
        if: success() && !env.ACT
        run: |
          aws s3 cp build-${{ github.sha }}.tar.gz s3://${{ inputs.s3-bucket }}/backend/builds/build-${{ github.sha }}.tar.gz
        working-directory: ${{ inputs.working-directory }}

  deploy:
    needs: build-test
    runs-on: ${{ inputs.deploy-runner }}
    steps:
      - name: AWS Auth
        if: ${{ !env.ACT }}
        uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502
        with:
          role-to-assume: ${{ secrets.aws-role-arn }}
          aws-region: ${{ inputs.aws-region }}

      - name: Download & Extract
        if: ${{ !env.ACT }}
        run: |
          rm -rf deploy-temp && mkdir -p deploy-temp
          aws s3 cp s3://${{ inputs.s3-bucket }}/backend/builds/build-${{ github.sha }}.tar.gz deploy-temp/artifact.tar.gz
          cd deploy-temp && tar -xzf artifact.tar.gz

      - name: Deployment
        if: ${{ !env.ACT }}
        shell: bash
        run: |
          if [[ "${{ inputs.debug_enabled }}" == "true" ]]; then set -x; fi

          TARGET_DIR=$(echo "${{ inputs.deploy-path }}" | xargs)
          ENV_SOURCE=$(echo "${{ inputs.env-source-path }}" | xargs)
          SERVICE_NAME="${{ inputs.serviceName }}" 
          APP_ROOT_DIR="$GITHUB_WORKSPACE/deploy-temp" 
          
          echo "Deploying Python backend to: $TARGET_DIR"
          mkdir -p "$TARGET_DIR"
          
          rsync -a --delete "$APP_ROOT_DIR/" "$TARGET_DIR/"

          if [ -f "$ENV_SOURCE" ]; then
            cp "$ENV_SOURCE" "$TARGET_DIR/.env"
            echo "Env restored"
          else
            echo "ERROR: Master env not found at $ENV_SOURCE"
            exit 1
          fi

          echo "Restarting service: $SERVICE_NAME"
          # Only restart if the service file actually exists
          if systemctl list-units --full -all | grep -Fq "$SERVICE_NAME"; then
             sudo systemctl restart $SERVICE_NAME || sudo systemctl start $SERVICE_NAME
          else
             echo "Warning: Service $SERVICE_NAME not found. Skipping restart."
          fi
          
          cd "$GITHUB_WORKSPACE"
          rm -rf deploy-temp
          echo "Python Backend Deployment Successful. Service: $SERVICE_NAME is managed by systemd."
