name: Python CI/CD

on:
  workflow_call:
    inputs:
      python-version: { type: string, default: '3.12' }
      working-directory: { type: string, default: '.' }
      aws-region: { type: string, required: true }
      deploy-runner: { type: string, default: 'self-hosted' }
      s3-bucket: { type: string, required: true }
      deploy-path: { type: string, required: true }
      env-source-path: { type: string, required: true }
      python-entry-point: { type: string, default: 'app/main.py', description: 'The main Python application entry point for PM2.' }
      debug_enabled: { type: boolean, default: false }
      serviceName: { type: string, default: 'island-haven-backend.service', description: 'The name of the systemd service to manage.' }
    secrets:
      aws-role-arn: { required: true }

permissions:
  contents: read
  id-token: write

jobs:
  build-test:
    runs-on: ${{ inputs.deploy-runner }}
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      # Add this step to install rsync
      - name: Install rsync
        run: |
          sudo apt-get update -y
          sudo apt-get install -y rsync

      - name: Set up Python
        run: |
          echo "Using system python: $(python3 --version)"
          # Verify venv module is available
          python3 -m venv --help > /dev/null || (sudo apt-get update && sudo apt-get install python3.12-venv -y)
      
      - name: Cache Python Dependencies
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57
        id: cache-python-deps
        with:
          path: ${{ inputs.working-directory }}/.venv
          # FIXED: We use '3.12' directly because we know that is the system version
          key: ${{ runner.os }}-python-3.12-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-python-3.12-
              
      - name: Install Dependencies & Audit
        run: |
          # Create and use a local virtual environment for the build
          python3 -m venv .venv
          source .venv/bin/activate
          python3 -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install safety
          safety check -r requirements.txt || echo "Safety check found issues, continuing..."
        working-directory: ${{ inputs.working-directory }}

      - name: Lint & Format (Ruff)
        run: |
          pip install ruff
          ruff check . # Check for errors
          ruff format . # Format code
          ruff check --fix .
        working-directory: ${{ inputs.working-directory }}
        continue-on-error: true

      - name: Test & Coverage
        run: |
          if [ -f pytest.ini ] || [ -d tests ]; then
            pip install pytest pytest-cov
            # Run tests with coverage and fail if coverage is below 85%
            pytest --cov=app --cov-report=xml --cov-report=term-missing --cov-fail-under=85
          fi
        working-directory: ${{ inputs.working-directory }}

      - name: Prepare Artifact
        run: |
          mkdir -p deploy-package
          # Exclude git, virtualenvs, etc.
          rsync -a ./ deploy-package/ --exclude .git --exclude venv --exclude __pycache__
          cd deploy-package
          tar -czf ../build-${{ github.sha }}.tar.gz .
        working-directory: ${{ inputs.working-directory }}

      - name: AWS Auth
        if: success() && !env.ACT
        uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502
        with:
          role-to-assume: ${{ secrets.aws-role-arn }}
          aws-region: ${{ inputs.aws-region }}

      - name: Upload to S3
        if: success() && !env.ACT
        run: |
          # Ensure backend/builds path is used
          aws s3 cp build-${{ github.sha }}.tar.gz s3://${{ inputs.s3-bucket }}/backend/builds/build-${{ github.sha }}.tar.gz
        working-directory: ${{ inputs.working-directory }}

  deploy:
    needs: build-test
    runs-on: ${{ inputs.deploy-runner }}
    steps:
      - name: AWS Auth
        if: ${{ !env.ACT }}
        uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502
        with:
          role-to-assume: ${{ secrets.aws-role-arn }}
          aws-region: ${{ inputs.aws-region }}

      - name: Download & Extract
        if: ${{ !env.ACT }}
        run: |
          rm -rf deploy-temp && mkdir -p deploy-temp
          # Path must match backend/builds prefix used in Upload
          aws s3 cp s3://${{ inputs.s3-bucket }}/backend/builds/build-${{ github.sha }}.tar.gz deploy-temp/artifact.tar.gz
          cd deploy-temp && tar -xzf artifact.tar.gz

      - name: Deployment
        if: ${{ !env.ACT }}
        shell: bash
        run: |
          # Conditionally enable debug output if debug_enabled is true
          if [[ "${{ inputs.debug_enabled }}" == "true" ]]; then
            set -x
          fi

          TARGET_DIR=$(echo "${{ inputs.deploy-path }}" | xargs)
          ENV_SOURCE=$(echo "${{ inputs.env-source-path }}" | xargs)
          SERVICE_NAME="${{ inputs.serviceName }}" 

          # --- Ensure TARGET_DIR is correct where artifact is extracted ---
          # The artifact is extracted into ./deploy-temp/ by the previous step.
          # So, your app's root is likely deploy-temp/
          APP_ROOT_DIR="$GITHUB_WORKSPACE/deploy-temp" 
          
          # --- Handle target directory ---
          echo "Deploying Python backend to: $TARGET_DIR"
          mkdir -p "$TARGET_DIR"
          
          # --- Sync files ---
          rsync -a --delete "$APP_ROOT_DIR/" "$TARGET_DIR/"

          # --- Restore .env ---
          if [ -f "$ENV_SOURCE" ]; then
            cp "$ENV_SOURCE" "$TARGET_DIR/.env"
            echo "Env restored"
          else
            echo "ERROR: Master env not found at $ENV_SOURCE"
            exit 1
          fi

          # --- Run Python Application Specific Tasks (e.g., Migrations) ---
          cd "$TARGET_DIR"

          # --- Manage Python Service with systemctl ---
          echo "Restarting Python backend service: $SERVICE_NAME"

          sudo systemctl restart $SERVICE_NAME || sudo systemctl start $SERVICE_NAME
          # --- Cleanup ---
          cd "$GITHUB_WORKSPACE"
          rm -rf deploy-temp
          echo "Python Backend Deployment Successful. Service: $SERVICE_NAME is managed by systemd."
